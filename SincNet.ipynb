{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SincNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "13j8STpGN8qJRmmAlFDpxTpqZw9YbLmKH",
      "authorship_tag": "ABX9TyNj7f/dUM9w+eglCSgMmVD3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhartha18101/Covid-19/blob/master/SincNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zmVH8MfAGJi",
        "colab_type": "code",
        "outputId": "eadad954-dae2-4112-e6aa-921046953683",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install torchaudio\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.5.0 in /usr/local/lib/python3.6/dist-packages (from torchaudio) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchaudio) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.0->torchaudio) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YcetPSLsajZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import torchaudio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQM58p5iGowI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files = glob.glob('/content/drive/My Drive/FInalModel/Data/*.wav')\n",
        "file_to_label = {}\n",
        "train_labels = pd.read_csv('/content/drive/My Drive/CovidData/meta/esc50.csv')\n",
        "for v,l in zip( train_labels.filename.values, train_labels.category.values):\n",
        "  v = \"/content/drive/My Drive/FInalModel/Data/\"+v\n",
        "  file_to_label[v]= l\n",
        "train_files1 = glob.glob('/content/drive/My Drive/FInalModel/Data/audio/*.wav')\n",
        "for v,l in zip( train_labels.filename.values, train_labels.category.values):\n",
        "  v = \"/content/drive/My Drive/FInalModel/Data/audio/\"+v\n",
        "  file_to_label[v]= l\n",
        "train_files = train_files + train_files1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dT5SYJ09JHVN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# file_to_label = {}\n",
        "\n",
        "# for v,l in zip( train_labels.filename.values, train_labels.category.values):\n",
        "#   v = \"/content/drive/My Drive/FInalModel/Data/\"+v\n",
        "#   file_to_label[v]= l\n",
        "#     # if(k == v and l=='sneezing'):\n",
        "#     #   file_to_label[k]= torch.tensor([0,1], dtype=torch.float32)\n",
        "#     # # if(k == v and l!='coughing' and l!='sneezing'):\n",
        "#     # #   file_to_label[k] = torch.tensor([0,0,1], dtype=torch.float32)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ZJHhffXnMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "list_labels = sorted(list(set(train_labels.category.values)))\n",
        "\n",
        "label_to_int = {k:v for v,k in enumerate(list_labels)}\n",
        "\n",
        "int_to_label = {v:k for k,v in label_to_int.items()}\n",
        "\n",
        "file_to_int = {k:label_to_int[v] for k,v in file_to_label.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA1y7ORRX9F5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len = 0\n",
        "for x in file_to_int:\n",
        "  i = file_to_int[x]\n",
        "  y = torch.zeros(1,50,dtype=  torch.float32)\n",
        "  y[0,i] = torch.tensor(1, dtype=  torch.float32 )\n",
        "  file_to_int[x] = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quyeiEJ1Ai2m",
        "colab_type": "code",
        "outputId": "e7a645aa-43f8-4226-c159-4cbee230ab86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "i=3\n",
        "y = torch.zeros(1,50,dtype=  torch.float32)\n",
        "y[0,i] = torch.tensor(1, dtype=  torch.float32 )\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1wpFR4qgG1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "keys = list(file_to_int)\n",
        "random.shuffle(keys)\n",
        "new = [(key, file_to_int[key]) for key in keys]\n",
        "file_to_int = dict(new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z7IbDC8J0Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signal, rate = torchaudio.load('/content/drive/My Drive/FInalModel/Data/1-19111-A-24.wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKWuIsESLfJi",
        "colab_type": "code",
        "outputId": "c1146ccf-6df3-4e8e-af54-a4c7c68b3a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "\n",
        "plt.plot(signal.t().numpy())\n",
        "plt.title('Sample Signal')\n",
        "plt.show()\n",
        "print('No. of samples: ' + str(signal.shape[1]))\n",
        "print('Smapling Rate: ' + str(rate))\n",
        "print('Time period: ' + str(signal.shape[0]/rate))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "No. of samples: 220500\n",
            "Smapling Rate: 44100\n",
            "Time period: 2.2675736961451248e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTtnUk0BZ6cf",
        "colab_type": "code",
        "outputId": "318825a1-d39c-49a4-f326-7f5d858260f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "signal, rate = torchaudio.load('/content/drive/My Drive/FInalModel/Data/1-19111-A-24.wav')\n",
        "signal = signal.reshape((1,1,220500))\n",
        "x = nn.Sequential(\n",
        "            SincConv_fast(80, 64, stride=8),\n",
        "            nn.BatchNorm1d(80),\n",
        "            nn.MaxPool1d(16, stride=2 ),\n",
        "            nn.LeakyReLU()) (signal)\n",
        "\n",
        "x1 = nn.Sequential(\n",
        "            nn.Conv1d(80,160, 64, 4),\n",
        "            nn.BatchNorm1d(160),\n",
        "            nn.AvgPool1d(8, stride=2 ),\n",
        "            nn.LeakyReLU()) (x)\n",
        "\n",
        "x2 = nn.Sequential(\n",
        "            nn.Conv1d(160,256, 32, 4),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.MaxPool1d(8, stride=1 ),\n",
        "            nn.ReLU()) (x1)\n",
        "\n",
        "x3 = nn.Sequential(\n",
        "            nn.Conv1d(256,256,32,2),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU()) (x2)\n",
        "\n",
        "x4 = nn.Sequential(\n",
        "            nn.Conv1d(256,512,32,2),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU()) (x3)\n",
        "      \n",
        "x5 = nn.Sequential(\n",
        "            nn.Conv1d(512,1024,16,2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU(),\n",
        "           ) (x4)\n",
        "\n",
        "x6 = nn.Sequential(\n",
        "            nn.Conv1d(1024,2048,16),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU(),\n",
        "           ) (x5)\n",
        "\n",
        "x7 = nn.Flatten()(x6)\n",
        "x8 = nn.Dropout()(x7)\n",
        "\n",
        "x9 = nn.Linear(20480,8192)(x8)\n",
        "x9 = nn.Linear(8192,2048)(x9)\n",
        "x9 = nn.Linear(2048, 512)(x9)\n",
        "x9 = nn.Linear(512, 256)(x9)\n",
        "x9 = nn.Linear(256, 50)(x9)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-5512e68666ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/FInalModel/Data/1-19111-A-24.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m220500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m x = nn.Sequential(\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mSincConv_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHgnfOvPF9Qn",
        "colab_type": "code",
        "outputId": "0b8da5f8-d831-430d-c0a2-3154569d07af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "print(x9.argmax())\n",
        "# plt.plot(x6[500].detach())\n",
        "# plt.show()\n",
        "# [1, 20480]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f97a8c1264dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx9\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# plt.plot(x6[500].detach())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# [1, 20480]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x9' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDf-nwxCixJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "\n",
        "def flip(x, dim):\n",
        "    xsize = x.size()\n",
        "    dim = x.dim() + dim if dim < 0 else dim\n",
        "    x = x.contiguous()\n",
        "    x = x.view(-1, *xsize[dim:])\n",
        "    x = x.view(x.size(0), x.size(1), -1)[:, getattr(torch.arange(x.size(1)-1, \n",
        "                      -1, -1), ('cpu','cuda')[x.is_cuda])().long(), :]\n",
        "    return x.view(xsize)\n",
        "\n",
        "\n",
        "def sinc(band,t_right):\n",
        "    y_right= torch.sin(2*math.pi*band*t_right)/(2*math.pi*band*t_right)\n",
        "    y_left= flip(y_right,0)\n",
        "\n",
        "    y=torch.cat([y_left,Variable(torch.ones(1)).cuda(),y_right])\n",
        "\n",
        "    return y\n",
        "    \n",
        "\n",
        "class SincConv_fast(nn.Module):\n",
        "    \"\"\"Sinc-based convolution\n",
        "    Parameters\n",
        "    ----------\n",
        "    in_channels : `int`\n",
        "        Number of input channels. Must be 1.\n",
        "    out_channels : `int`\n",
        "        Number of filters.\n",
        "    kernel_size : `int`\n",
        "        Filter length.\n",
        "    sample_rate : `int`, optional\n",
        "        Sample rate. Defaults to 16000.\n",
        "    Usage\n",
        "    -----\n",
        "    See `torch.nn.Conv1d`\n",
        "    Reference\n",
        "    ---------\n",
        "    Mirco Ravanelli, Yoshua Bengio,\n",
        "    \"Speaker Recognition from raw waveform with SincNet\".\n",
        "    https://arxiv.org/abs/1808.00158\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def to_mel(hz):\n",
        "        return 2595 * np.log10(1 + hz / 700)\n",
        "\n",
        "    @staticmethod\n",
        "    def to_hz(mel):\n",
        "        return 700 * (10 ** (mel / 2595) - 1)\n",
        "\n",
        "    def __init__(self, out_channels, kernel_size, sample_rate=16000, in_channels=1,\n",
        "                 stride=1, padding=0, dilation=1, bias=False, groups=1, min_low_hz=50, min_band_hz=50):\n",
        "\n",
        "        super(SincConv_fast,self).__init__()\n",
        "\n",
        "        if in_channels != 1:\n",
        "            #msg = (f'SincConv only support one input channel '\n",
        "            #       f'(here, in_channels = {in_channels:d}).')\n",
        "            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        \n",
        "        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n",
        "        if kernel_size%2==0:\n",
        "            self.kernel_size=self.kernel_size+1\n",
        "            \n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "\n",
        "        if bias:\n",
        "            raise ValueError('SincConv does not support bias.')\n",
        "        if groups > 1:\n",
        "            raise ValueError('SincConv does not support groups.')\n",
        "\n",
        "        self.sample_rate = sample_rate\n",
        "        self.min_low_hz = min_low_hz\n",
        "        self.min_band_hz = min_band_hz\n",
        "\n",
        "        # initialize filterbanks such that they are equally spaced in Mel scale\n",
        "        low_hz = 30\n",
        "        high_hz = self.sample_rate / 2 - (self.min_low_hz + self.min_band_hz)\n",
        "\n",
        "        mel = np.linspace(self.to_mel(low_hz),\n",
        "                          self.to_mel(high_hz),\n",
        "                          self.out_channels + 1)\n",
        "        hz = self.to_hz(mel)\n",
        "        \n",
        "\n",
        "        # filter lower frequency (out_channels, 1)\n",
        "        self.low_hz_ = nn.Parameter(torch.Tensor(hz[:-1]).view(-1, 1))\n",
        "\n",
        "        # filter frequency band (out_channels, 1)\n",
        "        self.band_hz_ = nn.Parameter(torch.Tensor(np.diff(hz)).view(-1, 1))\n",
        "\n",
        "        # Hamming window\n",
        "        #self.window_ = torch.hamming_window(self.kernel_size)\n",
        "        n_lin=torch.linspace(0, (self.kernel_size/2)-1, steps=int((self.kernel_size/2))) # computing only half of the window\n",
        "        self.window_=0.54-0.46*torch.cos(2*math.pi*n_lin/self.kernel_size);\n",
        "\n",
        "\n",
        "        # (1, kernel_size/2)\n",
        "        n = (self.kernel_size - 1) / 2.0\n",
        "        self.n_ = 2*math.pi*torch.arange(-n, 0).view(1, -1) / self.sample_rate # Due to symmetry, I only need half of the time axes\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "    def forward(self, waveforms):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        waveforms : `torch.Tensor` (batch_size, 1, n_samples)\n",
        "            Batch of waveforms.\n",
        "        Returns\n",
        "        -------\n",
        "        features : `torch.Tensor` (batch_size, out_channels, n_samples_out)\n",
        "            Batch of sinc filters activations.\n",
        "        \"\"\"\n",
        "\n",
        "        self.n_ = self.n_.to(waveforms.device)\n",
        "\n",
        "        self.window_ = self.window_.to(waveforms.device)\n",
        "\n",
        "        low = self.min_low_hz  + torch.abs(self.low_hz_)\n",
        "        \n",
        "        high = torch.clamp(low + self.min_band_hz + torch.abs(self.band_hz_),self.min_low_hz,self.sample_rate/2)\n",
        "        band=(high-low)[:,0]\n",
        "        \n",
        "        f_times_t_low = torch.matmul(low, self.n_)\n",
        "        f_times_t_high = torch.matmul(high, self.n_)\n",
        "\n",
        "        band_pass_left=((torch.sin(f_times_t_high)-torch.sin(f_times_t_low))/(self.n_/2))*self.window_ # Equivalent of Eq.4 of the reference paper (SPEAKER RECOGNITION FROM RAW WAVEFORM WITH SINCNET). I just have expanded the sinc and simplified the terms. This way I avoid several useless computations. \n",
        "        band_pass_center = 2*band.view(-1,1)\n",
        "        band_pass_right= torch.flip(band_pass_left,dims=[1])\n",
        "        \n",
        "        \n",
        "        band_pass=torch.cat([band_pass_left,band_pass_center,band_pass_right],dim=1)\n",
        "\n",
        "        \n",
        "        band_pass = band_pass / (2*band[:,None])\n",
        "        \n",
        "\n",
        "        self.filters = (band_pass).view(\n",
        "            self.out_channels, 1, self.kernel_size)\n",
        "\n",
        "        return F.conv1d(waveforms, self.filters, stride=self.stride,\n",
        "                        padding=self.padding, dilation=self.dilation,\n",
        "                         bias=None, groups=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJZj5NRSIxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class SampleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(SampleCNN, self).__init__()\n",
        "\n",
        "          self.conv1 = nn.Sequential(\n",
        "            SincConv_fast(80, 64, stride=8 ),\n",
        "            nn.BatchNorm1d(80),\n",
        "            nn.MaxPool1d(16, stride=2 ),\n",
        "            nn.LeakyReLU()) \n",
        "\n",
        "          self.conv2 = nn.Sequential(\n",
        "            # SincConv_fast(160, 64, in_channels=80, stride=4),\n",
        "            nn.Conv1d(80,160, 64, 4),\n",
        "            nn.BatchNorm1d(160),\n",
        "            nn.AvgPool1d(8, stride=2 ),\n",
        "            nn.LeakyReLU()) \n",
        "\n",
        "          self.conv3 = nn.Sequential(\n",
        "            # SincConv_fast(256, 32, in_channels=160, stride=4), \n",
        "            nn.Conv1d(160,256, 32, 4),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.MaxPool1d(8, stride=1 ),\n",
        "            nn.ReLU()) \n",
        "\n",
        "          self.conv4 = nn.Sequential(\n",
        "            nn.Conv1d(256,256,32,2),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU()) \n",
        "\n",
        "          self.conv5 = nn.Sequential(\n",
        "            nn.Conv1d(256,512,32,2),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU())\n",
        "      \n",
        "          self.conv6 = nn.Sequential(\n",
        "            nn.Conv1d(512,1024,16,2),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU(),\n",
        "           ) \n",
        "\n",
        "          self.conv7 = nn.Sequential(\n",
        "            nn.Conv1d(1024,2048,16),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.MaxPool1d(4, stride=1 ),\n",
        "            nn.ReLU(),\n",
        "           ) \n",
        "\n",
        "          self.fc = nn.Flatten()\n",
        "          self.dp = nn.Dropout()\n",
        " \n",
        "          self.fc1 = nn.Linear(20480,8192) \n",
        "          self.fc2 = nn.Linear(8192,2048) \n",
        "          self.fc3 = nn.Linear(2048, 512) \n",
        "          self.fc4 = nn.Linear(512, 256) \n",
        "          self.fc5 = nn.Linear(256, 50) \n",
        "          self.activation = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "        # # [1,1,220500]\n",
        "        # self.conv1 = nn.Sequential(\n",
        "        #     SincConv_fast(16000, 80, stride=16 ),\n",
        "        #     nn.BatchNorm1d(128),\n",
        "        #     nn.MaxPool1d(3, stride=1),\n",
        "        #     nn.ReLU())\n",
        "        \n",
        "        # # [1, 80, 27552]\n",
        "        # self.conv2 = nn.Sequential(\n",
        "        #     nn.Conv1d(128, 256, kernel_size=16, stride=16, padding=0 ),\n",
        "        #     nn.BatchNorm1d(256),\n",
        "        #     nn.ReLU(),\n",
        "            \n",
        "        #     # nn.MaxPool1d(3, stride=1)\n",
        "        #     )\n",
        "        # # [1, 160, 6878]\n",
        "        # self.conv3 = nn.Sequential(\n",
        "        #     nn.Conv1d(256, 512, kernel_size=16, stride=8, padding=1 ),\n",
        "        #     # nn.BatchNorm1d(256),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.MaxPool2d(3,stride=1),\n",
        "        #     nn.Dropout(0.5),\n",
        "        #     nn.Flatten()\n",
        "        #     # nn.MaxPool1d(3, stride=1)\n",
        "        #     )\n",
        "        \n",
        "        # # [1, 256, 3432]\n",
        "\n",
        "        # # [1, 256, 3425])\n",
        "        # # self.conv4 = nn.Sequential(\n",
        "        # #     nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1 ),\n",
        "        # #     # nn.BatchNorm1d(256),\n",
        "        # #     nn.ReLU(),\n",
        "        # #     nn.MaxPool2d(3,stride=1),\n",
        "        # #     nn.Dropout(0.5),\n",
        "        # #     nn.Flatten()\n",
        "        # #     )\n",
        "        \n",
        "        # # self.flatten =nn.Flatten()\n",
        "        \n",
        "        # 1 x 512 \n",
        "        # self.fc1= nn.Linear(5100, 2)\n",
        "        \n",
        "        # # self.fc = nn.Linear(512)\n",
        "        # # self.fc2 = nn.Linear(2048, 512)\n",
        "        # # self.fc3 = nn.Linear(512, 64)\n",
        "        # # self.fc4 = nn.Linear(64,2)        \n",
        "        # self.activation = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out = self.conv7(out)\n",
        "       \n",
        "         \n",
        "        \n",
        "        out = self.fc(out)\n",
        "        out = self.dp(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        out = self.fc5(out) \n",
        "        logit = self.activation(out)\n",
        "\n",
        "        return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srZ_2aOFZ1oz",
        "colab_type": "code",
        "outputId": "67603383-ad5e-48a9-d772-5840253d70de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "model = SampleCNN()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001) \n",
        "criterion = nn.MSELoss() \n",
        "\n",
        "\n",
        "for epoch in range(300):  \n",
        "    j = 0\n",
        "    cor = 0\n",
        "    running_loss = 0.0\n",
        "    for  x in train_files :\n",
        "\n",
        "        signal, rate = torchaudio.load(x)\n",
        "        inputs = signal.reshape((1,1,220500))\n",
        "        label = file_to_int[x]\n",
        "        # label = torch.tensor(label, dtype = torch.float32)\n",
        "       \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "\n",
        "       \n",
        "        loss = criterion(outputs, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if(j%100==99):\n",
        "          print('running_loss')\n",
        "        if (torch.argmax(label) == torch.argmax(outputs)):\n",
        "           cor = cor+1\n",
        "        j = j+1\n",
        "    print('Epoch: {} Loss: {} Acc: {}'.format(epoch, running_loss, cor/1979))\n",
        "    running_loss = 0.0\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n",
            "running_loss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCmaQ9G2DsJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_files.remove('/content/drive/My Drive/FInalModel/Data/5-251489-A-24 (1).wav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go86-Tz9Qs_j",
        "colab_type": "code",
        "outputId": "3acae58b-b87d-4d21-bbc7-bcfbb086141b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "outputs.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1dpk6QbDx7C",
        "colab_type": "code",
        "outputId": "1cf47e03-28d3-43bf-e7bb-24df95f48ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'/content/drive/My Drive/FInalModel/Data/5-251489-A-24 (1).wav' in train_files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1lrXgU5N7pT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SampleCNN()\n",
        "example = torch.rand(1,1, 220500, dtype= torch.float32)\n",
        "# model.load_state_dict(torch.load('/content/drive/My Drive/Pytorch/good3'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsiOdY7XOCqx",
        "colab_type": "code",
        "outputId": "a7e99676-61af-47f9-b123-2f4d35456eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "traced_script_module = torch.jit.trace(model, (torch.rand(1, 1, 220500)) ,check_tolerance=1e-05, _force_outplace=True)\n",
        "traced_script_module\n",
        "traced_script_module.save('/content/drive/My Drive/Pytorch/script.zip')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/jit/__init__.py:1037: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
            "Not within tolerance rtol=1e-05 atol=1e-05 at input[0, 1] (0.3484496772289276 vs. 0.25080135464668274) and 1 other locations (100.00%)\n",
            "  check_tolerance, _force_outplace, True, _module_class)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdBUvInGyeT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/Pytorch/good3')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcp93p0Dz944",
        "colab_type": "code",
        "outputId": "308f37ee-2294-4000-e96c-5377c6c35d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "newmodel = SampleCNN()\n",
        "newmodel.load_state_dict(torch.load('/content/drive/My Drive/Pytorch/good'))\n",
        "cor = 0\n",
        "for i, x in enumerate(train_files, 0):\n",
        "  signal, rate = torchaudio.load(x)\n",
        "  inputs = signal.reshape((1,1,220500))\n",
        "  label = file_to_label[train_files[0]].reshape((1,3))\n",
        "        \n",
        "  outputs = newmodel(inputs)\n",
        "  \n",
        "  if (torch.argmax(label) == torch.argmax(outputs)):\n",
        "    cor = cor+1\n",
        "acc = (cor/130)*100\n",
        "print('Acc: {}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c0d736416686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnewmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSampleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnewmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Pytorch/good'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SampleCNN:\n\tMissing key(s) in state_dict: \"conv2.1.weight\", \"conv2.1.bias\", \"conv2.1.running_mean\", \"conv2.1.running_var\". \n\tUnexpected key(s) in state_dict: \"conv4.0.weight\", \"conv4.0.bias\", \"conv3.1.weight\", \"conv3.1.bias\", \"conv3.1.running_mean\", \"conv3.1.running_var\", \"conv3.1.num_batches_tracked\". \n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([512, 12750]) from checkpoint, the shape in current model is torch.Size([512, 13208]).\n\tsize mismatch for fc3.weight: copying a param with shape torch.Size([3, 64]) from checkpoint, the shape in current model is torch.Size([2, 64]).\n\tsize mismatch for fc3.bias: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([2])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "getXqwYT2Eym",
        "colab_type": "code",
        "outputId": "02a0ac03-1bf8-48fb-e473-794ad98aff38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "test_files = glob.glob('/content/drive/My Drive/Pytorch/Cough/*wav')\n",
        "cor = 00\n",
        "# for i, x in enumerate(test_files, 0):\n",
        "# signal, rate = torchaudio.load(test_files[6])\n",
        "  # signal = torchaudio\n",
        "inputs = signal.reshape((1,1,220500))\n",
        "label = torch.tensor([1,0,0], dtype = torch.float32)\n",
        "        \n",
        "outputs = model(inputs)\n",
        "  \n",
        "  # if (torch.argmax(label) == torch.argmax(outputs)):\n",
        "    # cor = cor+1\n",
        "# acc = (cor/i)*100\n",
        "# print(' Test Acc: {}'.format(acc))\n",
        "outputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-9b03e3081e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# signal = torchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m220500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 1, 220500]' is invalid for input of size 342026"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZJPb8-ZbSVv",
        "colab_type": "code",
        "outputId": "11209918-db03-4aac-b643-41da4294e190",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(file_to_label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqpo4ZwfZphC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# j = 0\n",
        "# model = SampleCNN()\n",
        "# signal, rate = torchaudio.load(train_files[0])\n",
        "# inputs = signal.reshape((1,1,220500))\n",
        "# # outputs = model(inputs)\n",
        "# optimizer = optim.Adam(model.parameters(), lr = 0.0001) \n",
        "# criterion = nn.CrossEntropyLoss( ) \n",
        "# # loss = criterion(outputs, torch.tensor( file_to_label[train_files[0]] ))\n",
        "# label = file_to_label[train_files[0]].reshape((1,3))\n",
        "#         # labels = labels.reshape([1,3]\n",
        "\n",
        "#         # zero the parameter gradients\n",
        "# optimizer.zero_grad()\n",
        "\n",
        "#         # forward + backward + optimize\n",
        "# outputs = model(inputs)\n",
        "# # outputs = outputs.squeeze_()\n",
        "# # label = label.squeeze_()\n",
        "# loss = criterion(outputs, label )\n",
        "# print(outputs.size())\n",
        "# label.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqihRuSsTbZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# m = nn.Sequential(\n",
        "#             nn.Conv1d(256, 512, kernel_size=3, stride=2, padding=1 ),\n",
        "#             # nn.BatchNorm1d(256),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(3,stride=1),\n",
        "#             nn.Dropout(0.4),\n",
        "#             nn.Flatten()\n",
        "#             )\n",
        "# input = torch.randn(1, 256, 22500)\n",
        "# # input = signal.reshape((1,1,220500))\n",
        "# signal4 = m(input)\n",
        "# print(signal4.size())\n",
        "# plt.plot(signal4[0][45].detach())\n",
        "# plt.title('Sample Signal')\n",
        "# plt.show()\n",
        "\n",
        "# # print('No. of samples: ' + str(signal1.shape[1]))\n",
        "# # print('Smapling Rate: ' + str(rate))\n",
        "# # print('Time period: ' + str(signal1.shape[0]/rate))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}